{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Instructions\n",
    "\n",
    "Please read through all cells in this notebook carefully.\n",
    "\n",
    "**⭐Tasks that you need to do to complete the study are marked by stars.**"
   ],
   "metadata": {
    "id": "yzghHS5Hxxso"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Background questions\n",
    "\n",
    "**⭐ In the code block below, please answer the questions.**"
   ],
   "metadata": {
    "id": "ZyUm3xNsjhwt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# How many months/years of Python coding experience do you have?\n",
    "# ANSWER HERE:\n",
    "\n",
    "# Do you have any experience with machine learning (ML) programming? If yes, how many months/years?\n",
    "# ANSWER HERE:"
   ],
   "metadata": {
    "id": "shc72nSnjZ2l"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Installing and importing libraries\n",
    "\n",
    "⭐**Please run the next cell to install required libraries. If prompted, restart the runtime after running the cell using the \"restart runtime\" button at the bottom of the output.**"
   ],
   "metadata": {
    "id": "g1WnqpAF1GhX"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NW8MKqaSytKF"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn==1.3.2\n",
    "!pip install git+https://github.com/sibyl-dev/pyreal.git"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "\n",
    "In this task, we will ask you to generate *feature contribution explanations* of ML model predictions using the Pyreal python library.\n",
    "\n",
    "A **feature contribution explanation** shows how much each feature contributed to an ML model's prediction. Contributions are negative if a given feature value descreased the model prediction, and positive it it increased the model prediction.\n",
    "\n",
    "For example, consider a model that predicts the sale price of a house. A feature contribution explanation may tell you that the price increased by \\$8,000 because the house is in a good neighorbood, and decreased by \\$1,000 because it has two bedrooms. This information could be shown as a table with the following data:\n",
    "\n",
    "| Feature | Value | Contribution |\n",
    "|---|---|---|\n",
    "| Neighborhood Quality | Good | 8000 |\n",
    "| Bedrooms | 2 | -1000 |\n",
    "\n",
    "## How to Use Pyreal\n",
    "\n",
    "Pyreal is python library that generates ML model explanations such as feature contribution explanations.\n",
    "\n",
    "To use Pyreal, you must first make a RealApp object, which takes in data, a trained ML model, and a list of transformers. We will provide any data, model, or transformers you need to complete the tasks in this study.\n",
    "\n",
    "You can then use the RealApp to generate explanations, and then use Pyreal's **visualize** module to make graphs of the explanations.\n",
    "\n",
    "**⭐ Run the sample code below for an example of how to use Pyreal. You can use/copy this code throughout the study as needed.**\n",
    "\n",
    "For more information on how to use Pyreal, you can consult the [documentation](https://dtail.gitbook.io/pyreal). However, the sample code below should be sufficient to complete this user study.\n"
   ],
   "metadata": {
    "id": "dQFuo5HDzxm_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import joblib\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from pyreal import RealApp\n",
    "from pyreal.visualize import feature_bar_plot\n",
    "\n",
    "URL_BIKE = \"https://raw.githubusercontent.com/sibyl-dev/datasets/main/datasets/bike-sharing/\"\n",
    "\n",
    "# Required components - these will be given to you\n",
    "data_train = pd.read_csv(URL_BIKE + \"bike-sharing_train-data.csv\")\n",
    "y_train = data_train[\"cnt\"]\n",
    "X_train = data_train.drop(columns=\"cnt\")\n",
    "pipeline = joblib.load(urllib.request.urlopen(URL_BIKE + \"bike-sharing_pipeline.pkl\"))\n",
    "days_of_interest = pd.read_csv(URL_BIKE + \"bike-sharing_input.csv\")\n",
    "\n",
    "# Use this sample code for the tasks below\n",
    "# Create new explanation application object from the sklearn pipeline\n",
    "realapp = RealApp.from_sklearn(pipeline, X_train=X_train, y_train=y_train)\n",
    "\n",
    "# Produce a feature contribution explanations\n",
    "exp = realapp.produce_feature_contributions(days_of_interest)\n",
    "\n",
    "# Visualize the explanations\n",
    "feature_bar_plot(exp[0], num_features=8, select_by=\"absolute\")\n",
    "feature_bar_plot(exp[1], num_features=8, select_by=\"absolute\")\n",
    "feature_bar_plot(exp[2], num_features=8, select_by=\"absolute\")"
   ],
   "metadata": {
    "id": "38fMvxbYy7_G"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**⭐ Run the cell below to initialize data access URLs.**\n"
   ],
   "metadata": {
    "id": "Jrv3ETBVzbpO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "URL_BASE = \"https://raw.githubusercontent.com/sibyl-dev/datasets/main/datasets/\"\n",
    "URL_CALIFORNIA = URL_BASE + \"california-housing/\"\n",
    "URL_CHURN = URL_BASE + \"cell-phone-churn/\"\n",
    "URL_STUDENT = URL_BASE + \"student-performance/\""
   ],
   "metadata": {
    "id": "Pcl53M-Tpca1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset 1: Iranian Churn data\n",
    "\n",
    "### Preparing data and model\n",
    "\n",
    "We will be asking you to generate interpretable explanations on multiple datasets. We will begin with the [Iranian Churn Dataset](https://archive.ics.uci.edu/dataset/563/iranian+churn+dataset).\n",
    "\n",
    "In this dataset, each row represents a customer of a cell phone company. The target variable we are predicting is whether that customer will churn (ie., cancel their subscription with the company) after one year of service.\n",
    "\n",
    "**⭐Run the following cell to load the training data, the pretrained ML model, and a list of data transformers for this dataset.**"
   ],
   "metadata": {
    "id": "ziVVIdku1d52"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import urllib\n",
    "\n",
    "# Load in data\n",
    "data_train = pd.read_csv(URL_CHURN + \"cell-phone-churn_train-data.csv\")\n",
    "y_train = data_train[\"Churn\"]\n",
    "X_train = data_train.drop(columns=\"Churn\")\n",
    "\n",
    "# Load in sklearn pipeline\n",
    "pipeline = joblib.load(urllib.request.urlopen(URL_CHURN + \"cell-phone-churn_pipeline.pkl\"))"
   ],
   "metadata": {
    "id": "wmTAelWS1bTt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generating explanations\n",
    "\n",
    "In the following cell, we load in a few dataset customers of interest.\n",
    "\n",
    "**⭐Generate one feature contribution explanation per customer, explaining the model's prediction on these customers. The explanations should be presented as bar plots showing the 8 features that contribute the most (absolute value).**\n",
    "\n",
    "If you have done so correctly, you should end up with 3 bar plot explanations. The first should look similiar (though possibly not exactly) like the example below:\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1SwmHMtgu7E2KUpwhObV4hutzCgw4_0c7)\n"
   ],
   "metadata": {
    "id": "yZ3tYR0NBCSr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "customers_of_interest = pd.read_csv(URL_CHURN + \"cell-phone-churn_input.csv\")\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# FOLLOW THE EXAMPLE OF THE SAMPLE CODE ABOVE\n",
    "# YOU SHOULD GENERATE 3 BAR PLOT GRAPHS TOTAL"
   ],
   "metadata": {
    "id": "oamF39qcArnE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## California Housing Dataset\n",
    "\n",
    "Next, we will ask you to make interpretable explanations on the [California Housing Dataset]()\n",
    "\n",
    "In this dataset, each row refers to a block of houses in California, and the target variable to predict is the median price of houses in this block.\n",
    "\n",
    "**⭐Run the following cell to load the training data, the pretrained ML model, and a list of data transformers for this dataset.**"
   ],
   "metadata": {
    "id": "BvO_a7EtC-3U"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Load in data\n",
    "data_train = pd.read_csv(URL_CALIFORNIA + \"california-housing_train-data.csv\")\n",
    "y_train = data_train[\"MedianPrice\"]\n",
    "X_train = data_train.drop(columns=\"MedianPrice\")\n",
    "\n",
    "# Load in sklearn pipeline\n",
    "pipeline = joblib.load(urllib.request.urlopen(URL_CALIFORNIA + \"california-housing_pipeline.pkl\"))"
   ],
   "metadata": {
    "id": "vg-dRvALD4Cg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generating explanations\n",
    "\n",
    "In the following cell, we load in a few dataset housing blocks of interest.\n",
    "\n",
    "**⭐Generate one feature contribution explanation per block, explaining the model's prediction on these blocks. The explanations should be presented as bar plots showing the 8 features that contribute the most (absolute value).**\n",
    "\n",
    "If you have done so correctly, you should end up with 3 bar plot explanations."
   ],
   "metadata": {
    "id": "5C-Jk3TPxeaB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "blocks_of_interest = pd.read_csv(URL_CALIFORNIA + \"california-housing_input.csv\")\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# FOLLOW THE EXAMPLE OF THE SAMPLE CODE ABOVE\n",
    "# YOU SHOULD GENERATE 3 BAR PLOT GRAPHS TOTAL"
   ],
   "metadata": {
    "id": "ZE14yWQPvR87"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Student Performance Dataset\n",
    "\n",
    "Next, we will ask you to make interpretable explanations on the [Student Performance Dataset]()\n",
    "\n",
    "In this dataset, each row refers to a student at a school in Portugal, and the target variable to predict is whether they will pass or fail a class.\n",
    "\n",
    "**⭐Run the following cell to load the training data, the pretrained ML model, and a list of data transformers for this dataset.**"
   ],
   "metadata": {
    "id": "lN0CLBAnz8m-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Load in data\n",
    "data_train = pd.read_csv(URL_STUDENT + \"student-performance_train-data.csv\")\n",
    "y_train = data_train[\"Pass\"]\n",
    "X_train = data_train.drop(columns=\"Pass\")\n",
    "\n",
    "# Load in sklearn pipeline\n",
    "pipeline = joblib.load(urllib.request.urlopen(URL_STUDENT + \"student-performance_pipeline.pkl\"))"
   ],
   "metadata": {
    "id": "Ql7BL17a0LDY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generating explanations\n",
    "\n",
    "In the following cell, we load in a few dataset students of interest.\n",
    "\n",
    "**⭐Generate one feature contribution explanation per student, explaining the model's prediction on these students. The explanations should be presented as bar plots showing the 8 features that contribute the most (absolute value).**\n",
    "\n",
    "If you have done so correctly, you should end up with 3 bar plot explanations.\n"
   ],
   "metadata": {
    "id": "rDzz5z511mGa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "students_of_interest = pd.read_csv(URL_STUDENT + \"student-performance_input.csv\")\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# FOLLOW THE EXAMPLE OF THE SAMPLE CODE ABOVE\n",
    "# YOU SHOULD GENERATE 3 BAR PLOT GRAPHS TOTAL"
   ],
   "metadata": {
    "id": "sgqRD7Kb0TWt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "YlP878JdYpM_"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
